{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48wkMoJzMgyb"
      },
      "source": [
        "## 1. C√†i ƒë·∫∑t & Fix L·ªói"
      ],
      "id": "48wkMoJzMgyb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQNploZWMgyd",
        "outputId": "89173657-c86a-4671-cc1a-e75e17edc87a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.233)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.11\n",
            "    Uninstalling sympy-1.11:\n",
            "      Successfully uninstalled sympy-1.11\n",
            "Successfully installed sympy-1.14.0\n",
            "N·∫øu c√≥ n√∫t Restart Session, h√£y b·∫•m n√≥\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install ultralytics kaggle\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "import cv2\n",
        "import random\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "\n",
        "print(\"N·∫øu c√≥ n√∫t Restart Session, h√£y b·∫•m n√≥\")"
      ],
      "id": "NQNploZWMgyd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdWsQb8fMgyf"
      },
      "source": [
        "## 2. T·∫£i Dataset (Roboflow + MUID-IITR)"
      ],
      "id": "vdWsQb8fMgyf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDIlf6lWMgyf",
        "outputId": "59ffbe2b-9255-437c-eca1-be699626ceb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/raw_datasets\n",
            "ƒêang t·∫£i ds_notebook2...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   3355      0 --:--:-- --:--:-- --:--:--  3348\n",
            "100 12.4M  100 12.4M    0     0  11.1M      0  0:00:01  0:00:01 --:--:-- 11.1M\n",
            "ƒêang t·∫£i ds_person...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   1655      0 --:--:-- --:--:-- --:--:--  1655\n",
            "100  677k  100  677k    0     0   572k      0  0:00:01  0:00:01 --:--:-- 1211k\n",
            "\n",
            "--- C·∫§U H√åNH KAGGLE ƒê·ªÇ T·∫¢I DATASET 'B·∫†CH KIM' (MUID-IITR) ---\n",
            "‚úÖ ƒê√£ x√°c th·ª±c Kaggle th√†nh c√¥ng!\n",
            "ƒêang t·∫£i MUID-IITR Dataset (Platinum) v·ªõi ID m·ªõi...\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshyataragi/mobilephoneusagedatasetiitr\n",
            "License(s): unknown\n",
            "Downloading mobilephoneusagedatasetiitr.zip to /content/raw_datasets/muid\n",
            " 97% 592M/610M [00:01<00:00, 271MB/s]\n",
            "100% 610M/610M [00:01<00:00, 378MB/s]\n",
            "ƒêang gi·∫£i n√©n /content/raw_datasets/muid/mobilephoneusagedatasetiitr.zip...\n",
            "replace /content/raw_datasets/muid/labels.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n MUID-IITR th√†nh c√¥ng!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil # Th√™m import shutil n·∫øu ch∆∞a c√≥\n",
        "from google.colab import files # Th√™m import files n·∫øu ch∆∞a c√≥\n",
        "\n",
        "!mkdir -p /content/raw_datasets\n",
        "%cd /content/raw_datasets\n",
        "\n",
        "# 1. T·∫£i Roboflow Datasets (C∆° b·∫£n)\n",
        "datasets_links = [\n",
        "    # --- USER PROVIDED DATASETS ---\n",
        "    (\"ds_headphones_1\", \"https://app.roboflow.com/ds/LEbTxrDC1Z?key=HUXuJNHJln\"), # Headphones 1\n",
        "    (\"ds_headphones_2\", \"https://app.roboflow.com/ds/Xv2XRQJnkj?key=MCUrM6N8dJ\"), # Headphones 2\n",
        "    (\"ds_headphones_3\", \"https://app.roboflow.com/ds/qqqEeSKAlk?key=GT1Xa65onI\"), # Headphones 3\n",
        "    (\"ds_headphones_4\", \"https://app.roboflow.com/ds/cKHwOqmuda?key=qL10KsWlBt\"), # Headphones 4\n",
        "    (\"ds_book\", \"https://app.roboflow.com/ds/YXgXnzG1N6?key=hVHJmLqpMM\"),         # Book\n",
        "    (\"ds_book2\", \"https://app.roboflow.com/ds/dS9CSjxjCY?key=GCnf1k3d5L\"),        # Book2\n",
        "    (\"ds_book3\", \"https://app.roboflow.com/ds/PwRwV0c1jL?key=FgXbXeqlpH\"),        # Book3\n",
        "    (\"ds_phone\", \"https://app.roboflow.com/ds/5ReObgnLbQ?key=HTPSgVzDLW\"),        # Phone\n",
        "    (\"ds_phone2\", \"https://app.roboflow.com/ds/f9k54F7Azq?key=eYssUekSYc\"),       # Phone 2\n",
        "    (\"ds_notebook\", \"https://app.roboflow.com/ds/8ffU7TCBvG?key=1dUkZaVWbo\"),     # Notebook\n",
        "    (\"ds_notebook2\", \"https://app.roboflow.com/ds/n3eM0zBg8H?key=fQegfhKivl\"),    # Notebook2\n",
        "    (\"ds_person\", \"https://app.roboflow.com/ds/PwRwV0c1jL?key=FgXbXeqlpH\"),       # Person\n",
        "]\n",
        "\n",
        "for name, url in datasets_links:\n",
        "    if not os.path.exists(name):\n",
        "        print(f\"ƒêang t·∫£i {name}...\")\n",
        "        !mkdir -p {name}\n",
        "        !curl -L \"{url}\" > {name}/dataset.zip\n",
        "        !unzip -q {name}/dataset.zip -d {name}\n",
        "        !rm {name}/dataset.zip\n",
        "\n",
        "# 2. T·∫£i Dataset N√¢ng Cao t·ª´ Kaggle (MUID-IITR)\n",
        "print(\"\\n--- C·∫§U H√åNH KAGGLE ƒê·ªÇ T·∫¢I DATASET 'B·∫†CH KIM' (MUID-IITR) ---\")\n",
        "\n",
        "if not os.path.exists(\"/root/.kaggle\"):\n",
        "    !mkdir -p /root/.kaggle\n",
        "\n",
        "if not os.path.exists(\"/content/kaggle.json\"):\n",
        "    print(\"‚ö†Ô∏è Ch∆∞a th·∫•y file kaggle.json. Vui l√≤ng upload file kaggle.json ngay b√¢y gi·ªù:\")\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        print(f'ƒê√£ nh·∫≠n file \"{fn}\" v·ªõi k√≠ch th∆∞·ªõc {len(uploaded[fn])} bytes')\n",
        "        !mv {fn} /content/kaggle.json\n",
        "\n",
        "if os.path.exists(\"/content/kaggle.json\"):\n",
        "    !cp /content/kaggle.json /root/.kaggle/\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "    print(\"‚úÖ ƒê√£ x√°c th·ª±c Kaggle th√†nh c√¥ng!\")\n",
        "\n",
        "    # T·∫£i MUID-IITR (Platinum - Phone Specialist) v·ªõi ID m·ªõi\n",
        "    print(\"ƒêang t·∫£i MUID-IITR Dataset (Platinum) v·ªõi ID m·ªõi...\")\n",
        "    muid_target_dir = \"/content/raw_datasets/muid\"\n",
        "    os.makedirs(muid_target_dir, exist_ok=True)\n",
        "    !kaggle datasets download lakshyataragi/mobilephoneusagedatasetiitr -p {muid_target_dir}\n",
        "\n",
        "    # Gi·∫£i n√©n dataset\n",
        "    zip_file_path = os.path.join(muid_target_dir, \"mobilephoneusagedatasetiitr.zip\")\n",
        "    if os.path.exists(zip_file_path):\n",
        "        print(f\"ƒêang gi·∫£i n√©n {zip_file_path}...\")\n",
        "        !unzip -q {zip_file_path} -d {muid_target_dir}\n",
        "        # X√≥a file zip sau khi gi·∫£i n√©n ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng\n",
        "        os.remove(zip_file_path)\n",
        "        print(\"‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n MUID-IITR th√†nh c√¥ng!\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file {zip_file_path} sau khi t·∫£i. Vui l√≤ng ki·ªÉm tra l·∫°i ID dataset ho·∫∑c quy·ªÅn truy c·∫≠p.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è KH√îNG C√ì TH√îNG TIN KAGGLE. S·∫Ω b·ªè qua MUID, ch·ªâ d√πng Roboflow.\")"
      ],
      "id": "iDIlf6lWMgyf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- T·∫¢I DATASET CAMERA ·∫®N & TAI NGHE SI√äU NH·ªé T·ª™ ROBOFLOW ---\n",
        "# ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng ƒë·ªÉ model ph√°t hi·ªán ƒë∆∞·ª£c c√°c thi·∫øt b·ªã gian l·∫≠n tinh vi.\n",
        "\n",
        "import os\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c dataset ƒë·∫∑c bi·ªát\n",
        "!mkdir -p /content/raw_datasets/spy_devices\n",
        "%cd /content/raw_datasets/spy_devices\n",
        "\n",
        "print(\"ƒêang t·∫£i dataset Camera ·∫®n & Tai Nghe...\")\n",
        "\n",
        "# Dataset 1: Hidden Camera (Camera ng·ª•y trang)\n",
        "# Ngu·ªìn: Roboflow Universe (Public)\n",
        "!curl -L \"https://universe.roboflow.com/ds/XYZ_HIDDEN_CAM_LINK_PLACEHOLDER?key=YOUR_KEY\" > hidden_cam.zip\n",
        "# L∆∞u √Ω: Do link Roboflow thay ƒë·ªïi th∆∞·ªùng xuy√™n, h√£y thay link tr√™n b·∫±ng link b·∫°n l·∫•y t·ª´: \n",
        "# https://universe.roboflow.com/camera-88z4o/hiddencameradataset\n",
        "\n",
        "# Dataset 2: Tiny Earpiece (Tai nghe h·∫°t ƒë·∫≠u)\n",
        "# Ngu·ªìn gi·∫£ l·∫≠p: S·ª≠ d·ª•ng dataset 'Earphone' v√† augment nh·ªè l·∫°i\n",
        "\n",
        "print(\"‚ö†Ô∏è H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG: \")\n",
        "print(\"1. Sau khi train xong (ch·∫°y h·∫øt c√°c cell d∆∞·ªõi).\")\n",
        "print(\"2. File model t·ªët nh·∫•t s·∫Ω n·∫±m ·ªü: /content/runs/segment/train/weights/best.onnx\")\n",
        "print(\"3. B·∫°n h√£y t·∫£i file n√†y v·ªÅ v√† copy v√†o th∆∞ m·ª•c d·ª± √°n web: Intelligence-Test/public/models/anticheat_yolo11s.onnx\")\n",
        "print(\"4. Web s·∫Ω t·ª± ƒë·ªông load model m·ªõi n√†y ƒë·ªÉ ph√°t hi·ªán gian l·∫≠n.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mj_EtfyMgyg"
      },
      "source": [
        "## 3.  AI Auto-Labeling (Teacher: YOLO11x-seg)\n",
        "D√πng Teacher Model ƒë·ªÉ g√°n nh√£n l·∫°i to√†n b·ªô d·ªØ li·ªáu (bao g·ªìm c·∫£ MUID)."
      ],
      "id": "4mj_EtfyMgyg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGdjIr7dMgyh",
        "outputId": "71a221e5-f1c2-417c-a644-91c5b76611e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ƒêang x·ª≠ l√Ω /content/raw_datasets/ds1...\n",
            "   T·ªïng c·ªông 0 ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ƒêang x·ª≠ l√Ω /content/raw_datasets/muid...\n",
            "   T·ªïng c·ªông 888 ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 888/888 [01:47<00:00,  8.27it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load model Segmentation Teacher\n",
        "auto_label_model = YOLO('yolo11x-seg.pt')\n",
        "\n",
        "def auto_label_dataset(source_path, target_dir, is_video=False):\n",
        "    print(f\"ƒêang x·ª≠ l√Ω {source_path}...\")\n",
        "    images = []\n",
        "\n",
        "    for root, dirs, files in os.walk(source_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                images.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"   T·ªïng c·ªông {len(images)} ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\")\n",
        "\n",
        "    # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c Train/Valid\n",
        "    for split in ['train', 'valid']:\n",
        "        os.makedirs(f\"{target_dir}/{split}/images\", exist_ok=True)\n",
        "        os.makedirs(f\"{target_dir}/{split}/labels\", exist_ok=True)\n",
        "\n",
        "    random.shuffle(images)\n",
        "\n",
        "    for idx, img_path in enumerate(tqdm(images)):\n",
        "        split = 'train' if idx < len(images) * 0.8 else 'valid'\n",
        "\n",
        "        file_name = os.path.basename(img_path)\n",
        "        # Th√™m prefix ƒë·ªÉ tr√°nh tr√πng t√™n\n",
        "        prefix = f\"{os.path.basename(source_path)}_\"\n",
        "        unique_name = f\"{prefix}{file_name}\"\n",
        "\n",
        "        dest_img_path = f\"{target_dir}/{split}/images/{unique_name}\"\n",
        "        shutil.copy(img_path, dest_img_path)\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None: continue\n",
        "\n",
        "        # Run YOLO Segmentation (Teacher)\n",
        "        results = auto_label_model(image, verbose=False, conf=0.4)[0]\n",
        "        label_lines = []\n",
        "\n",
        "        if results.masks:\n",
        "            for i, mask in enumerate(results.masks.xyn):\n",
        "                cls_id = int(results.boxes.cls[i])\n",
        "                # COCO: 0=person, 67=cell phone, 73=book\n",
        "                # TARGET: 0=person, 1=phone, 2=book, 3=paper\n",
        "                my_cls_id = -1\n",
        "\n",
        "                if cls_id == 0:\n",
        "                    my_cls_id = 0 # person\n",
        "                elif cls_id == 67:\n",
        "                    my_cls_id = 1 # phone\n",
        "                elif cls_id == 73:\n",
        "                    my_cls_id = 2 # book\n",
        "\n",
        "                if my_cls_id != -1:\n",
        "                    mask_str = \" \".join(map(str, mask.flatten()))\n",
        "                    label_lines.append(f\"{my_cls_id} {mask_str}\")\n",
        "\n",
        "        if label_lines:\n",
        "            label_name = unique_name.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')\n",
        "            with open(f\"{target_dir}/{split}/labels/{label_name}\", 'w') as f:\n",
        "                f.write('\\n'.join(label_lines))\n",
        "\n",
        "OUTPUT_DIR = \"/content/merged_dataset\"\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "\n",
        "# 1. Auto-label ds1 (Roboflow)\n",
        "auto_label_dataset(\"/content/raw_datasets/ds1\", OUTPUT_DIR, is_video=False)\n",
        "\n",
        "# 2. Auto-label MUID (Platinum) - N·∫øu c√≥\n",
        "if os.path.exists(\"/content/raw_datasets/muid\"):\n",
        "    auto_label_dataset(\"/content/raw_datasets/muid\", OUTPUT_DIR, is_video=False)"
      ],
      "id": "mGdjIr7dMgyh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK5_PJoAMgyi"
      },
      "source": [
        "## 4. Merge c√°c Dataset c√≤n l·∫°i (ds2 - ds6)"
      ],
      "id": "eK5_PJoAMgyi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYbLx-JxMgyj",
        "outputId": "1cd4ac2c-9657-48da-8ef7-b63b48d35020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ƒêang g·ªôp c√°c dataset chu·∫©n (ds2-ds6) v√† chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng segmentation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ds_headphones_1 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 364/364 [00:00<00:00, 563.24it/s]\n",
            "ds_headphones_1 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:00<00:00, 548.95it/s]\n",
            "ds_headphones_1 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:00<00:00, 859.70it/s]\n",
            "ds_headphones_2 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 342/342 [00:00<00:00, 1016.33it/s]\n",
            "ds_headphones_2 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [00:00<00:00, 1082.47it/s]\n",
            "ds_headphones_2 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:00<00:00, 1230.09it/s]\n",
            "ds_headphones_3 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 2092.83it/s]\n",
            "ds_headphones_3 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:00<00:00, 1978.91it/s]\n",
            "ds_headphones_3 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 1883.81it/s]\n",
            "ds_headphones_4 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 364/364 [00:00<00:00, 522.77it/s]\n",
            "ds_headphones_4 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:00<00:00, 505.61it/s]\n",
            "ds_headphones_4 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:00<00:00, 557.60it/s]\n",
            "ds_book - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 350/350 [00:00<00:00, 548.43it/s]\n",
            "ds_book - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 580.74it/s]\n",
            "ds_book - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 720.04it/s]\n",
            "ds_book2 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [00:00<00:00, 768.82it/s]\n",
            "ds_book2 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 142/142 [00:00<00:00, 740.32it/s]\n",
            "ds_book2 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:00<00:00, 973.61it/s]\n",
            "ds_book3 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1322.56it/s]\n",
            "ds_phone - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1178/1178 [00:01<00:00, 958.54it/s]\n",
            "ds_phone - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:00<00:00, 1494.21it/s]\n",
            "ds_phone - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 1661.24it/s]\n",
            "ds_phone2 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1218/1218 [00:00<00:00, 1410.72it/s]\n",
            "ds_phone2 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 937.06it/s]\n",
            "ds_phone2 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [00:00<00:00, 764.68it/s]\n",
            "ds_notebook - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1814/1814 [00:01<00:00, 943.28it/s] \n",
            "ds_notebook - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 518/518 [00:00<00:00, 751.58it/s]\n",
            "ds_notebook - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 259/259 [00:00<00:00, 885.05it/s]\n",
            "ds_notebook2 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:00<00:00, 2676.29it/s]\n",
            "ds_notebook2 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71/71 [00:00<00:00, 2891.50it/s]\n",
            "ds_notebook2 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:00<00:00, 2781.98it/s]\n",
            "ds_person - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 3400.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " G·ªôp dataset ho√†n t·∫•t! Model n√†y s·∫Ω CHUY√äN TR·ªä V·∫¨T TH·ªÇ (Person, Phone, Book, Paper).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "TARGET_CLASSES = ['person', 'phone', 'material', 'headphones']\n",
        "\n",
        "CLASS_MAPPING = {\n",
        "    'person': 'person', 'student': 'person', 'face': 'person', 'head': 'person',\n",
        "    'phone': 'phone', 'mobile': 'phone', 'cell phone': 'phone', 'telephone': 'phone', 'smartphone': 'phone', 'ProductRecog - v2 2024-11-05 7:03am': 'phone',\n",
        "    'book': 'material', 'textbook': 'material', 'notebook': 'material', 'book - v12 2023-08-01 10:47am': 'material', 'Book': 'material', 'Notebook': 'material', 'closed': 'material', 'opened': 'material',\n",
        "    'paper': 'material', 'cheat': 'material', 'notes': 'material', 'document': 'material',\n",
        "    'headphone': 'headphones', 'headphones': 'headphones', 'earphone': 'headphones', 'headset': 'headphones', 'earbuds': 'headphones', 'Headphone': 'headphones',\n",
        "}\n",
        "\n",
        "os.makedirs(f\"{OUTPUT_DIR}/train/images\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/train/labels\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/valid/images\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/valid/labels\", exist_ok=True)\n",
        "\n",
        "def normalize_class(class_name):\n",
        "    class_name = class_name.lower().strip()\n",
        "    for key, target in CLASS_MAPPING.items():\n",
        "        if class_name == key:\n",
        "            if target == 'ignore': return -1\n",
        "            return TARGET_CLASSES.index(target)\n",
        "    return -1\n",
        "\n",
        "def find_data_yaml(start_dir):\n",
        "    for root, dirs, files in os.walk(start_dir):\n",
        "        if 'data.yaml' in files:\n",
        "            return os.path.join(root, 'data.yaml')\n",
        "    return None\n",
        "\n",
        "# Helper function to convert YOLO bounding box (xc yc w h) to segmentation polygon (x1 y1 x2 y2 x3 y3 x4 y4)\n",
        "def bbox_to_segment(bbox_coords):\n",
        "    try:\n",
        "        # bbox_coords is a list of strings: [x_center, y_center, width, height]\n",
        "        # Convert to float\n",
        "        xc, yc, w, h = map(float, bbox_coords)\n",
        "        # Calculate corner points (normalized)\n",
        "        x1, y1 = xc - w/2, yc - h/2  # Top-left\n",
        "        x2, y2 = xc + w/2, yc - h/2  # Top-right\n",
        "        x3, y3 = xc + w/2, yc + h/2  # Bottom-right\n",
        "        x4, y4 = xc - w/2, yc + h/2  # Bottom-left\n",
        "        return f\"{x1} {y1} {x2} {y2} {x3} {y3} {x4} {y4}\"\n",
        "    except ValueError:\n",
        "        return None # Return None if conversion fails\n",
        "\n",
        "good_datasets = datasets_links[0:]\n",
        "\n",
        "print(\"üîÑ ƒêang g·ªôp c√°c dataset chu·∫©n (ds2-ds6) v√† chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng segmentation...\")\n",
        "\n",
        "for ds_name, _ in good_datasets:\n",
        "    ds_path = f\"/content/raw_datasets/{ds_name}\"\n",
        "    yaml_path = find_data_yaml(ds_path)\n",
        "\n",
        "    if not yaml_path:\n",
        "        print(f\"{ds_name}: Kh√¥ng t√¨m th·∫•y data.yaml -> B·ªè qua.\")\n",
        "        continue\n",
        "\n",
        "    ds_root = os.path.dirname(yaml_path)\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    source_classes = data_config.get('names', [])\n",
        "\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        possible_img_dirs = [\n",
        "            os.path.join(ds_root, split, 'images'),\n",
        "            os.path.join(ds_root, split),\n",
        "            os.path.join(ds_path, split, 'images'),\n",
        "            os.path.join(ds_path, split)\n",
        "        ]\n",
        "        src_img_dir = None\n",
        "        for d in possible_img_dirs:\n",
        "            if os.path.exists(d) and (glob(f\"{d}/*.jpg\") or glob(f\"{d}/*.png\")):\n",
        "                src_img_dir = d\n",
        "                break\n",
        "        if not src_img_dir: continue\n",
        "\n",
        "        images = glob(f\"{src_img_dir}/*.jpg\") + glob(f\"{src_img_dir}/*.png\")\n",
        "        target_split = 'valid' if split in ['valid', 'test'] else 'train'\n",
        "\n",
        "        for img_path in tqdm(images, desc=f\"{ds_name} - {split}\"):\n",
        "            file_name = os.path.basename(img_path)\n",
        "            unique_name = f\"{ds_name}_{file_name}\"\n",
        "            shutil.copy(img_path, f\"{OUTPUT_DIR}/{target_split}/images/{unique_name}\")\n",
        "\n",
        "            label_name = file_name.replace('.jpg', '.txt').replace('.png', '.txt')\n",
        "            possible_label_paths = [\n",
        "                img_path.replace('/images/', '/labels/').replace(file_name, label_name),\n",
        "                os.path.join(ds_root, split, 'labels', label_name),\n",
        "                os.path.join(ds_path, split, 'labels', label_name)\n",
        "            ]\n",
        "            label_path = None\n",
        "            for p in possible_label_paths:\n",
        "                if os.path.exists(p):\n",
        "                    label_path = p\n",
        "                    break\n",
        "\n",
        "            if label_path:\n",
        "                new_labels = []\n",
        "                with open(label_path, 'r') as lf:\n",
        "                    for line in lf:\n",
        "                        parts = line.strip().split()\n",
        "                        if not parts: continue\n",
        "                        try:\n",
        "                            cls_id = int(parts[0])\n",
        "                            if cls_id < len(source_classes):\n",
        "                                cls_name = source_classes[cls_id]\n",
        "                                new_id = normalize_class(cls_name)\n",
        "                                if new_id != -1:\n",
        "                                    # Check if the label is a bounding box (5 parts) or segmentation (more than 5 parts)\n",
        "                                    if len(parts) == 5: # Assuming it's a bounding box: class x_c y_c w h\n",
        "                                        segment_coords = bbox_to_segment(parts[1:])\n",
        "                                        if segment_coords:\n",
        "                                            new_labels.append(f\"{new_id} {segment_coords}\")\n",
        "                                    else: # Already segmentation format (class x1 y1 x2 y2 ...)\n",
        "                                        new_labels.append(f\"{new_id} {' '.join(parts[1:])}\")\n",
        "                        except ValueError: continue\n",
        "\n",
        "                with open(f\"{OUTPUT_DIR}/{target_split}/labels/{unique_name.replace('.jpg','.txt').replace('.png','.txt')}\", 'w') as nf:\n",
        "                    nf.write('\\n'.join(new_labels))\n",
        "\n",
        "final_yaml = {\n",
        "    'path': OUTPUT_DIR,\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'nc': len(TARGET_CLASSES),\n",
        "    'names': TARGET_CLASSES\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/data.yaml\", 'w') as f:\n",
        "    yaml.dump(final_yaml, f)\n",
        "\n",
        "print(\"\\n G·ªôp dataset ho√†n t·∫•t! Model n√†y s·∫Ω CHUY√äN TR·ªä V·∫¨T TH·ªÇ (Person, Phone, Book, Paper).\")"
      ],
      "id": "IYbLx-JxMgyj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq379XPDMgyj"
      },
      "source": [
        "## 5. Train Model (Object Expert)"
      ],
      "id": "fq379XPDMgyj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntx3AoCsMgyk",
        "outputId": "a827a9df-5d5e-42cc-f644-15045585c453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/merged_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=anticheat_objects_v2_headphones, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Intelligence-Test-Models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1   1475452  ultralytics.nn.modules.head.Segment          [4, 32, 128, [128, 256, 512]] \n",
            "YOLO11s-seg summary: 203 layers, 10,083,836 parameters, 10,083,820 gradients, 33.1 GFLOPs\n",
            "\n",
            "Transferred 561/561 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2179.2¬±996.0 MB/s, size: 376.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/merged_dataset/train/labels... 7366 images, 1576 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7367/7367 1.9Kit/s 3.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/merged_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.3¬±0.6 ms, read: 324.5¬±68.9 MB/s, size: 40.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/merged_dataset/valid/labels... 2390 images, 221 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2390/2390 546.2it/s 4.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/merged_dataset/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      5.64G     0.7821      0.845     0.6092      1.108         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 1.9it/s 4:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.4it/s 52.5s\n",
            "                   all       2390       3598      0.867      0.763      0.843      0.599       0.86      0.748      0.822      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100       5.4G     0.7738      0.827     0.5995        1.1         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9it/s 39.1s\n",
            "                   all       2390       3598      0.892      0.757      0.844      0.596      0.883      0.746      0.827       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      5.55G     0.8184     0.9039     0.6398      1.123         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8it/s 41.0s\n",
            "                   all       2390       3598      0.865       0.76      0.834      0.583      0.858      0.745      0.813      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      5.34G     0.8486     0.9257     0.6967       1.14         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.1it/s 3:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8it/s 42.4s\n",
            "                   all       2390       3598      0.829       0.77      0.828       0.58      0.813      0.749      0.807      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      5.39G     0.8726     0.9649     0.7235      1.153         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.7it/s 44.3s\n",
            "                   all       2390       3598      0.863      0.729      0.824      0.573      0.862      0.709      0.801      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      5.42G     0.8722     0.9512     0.7297      1.158         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.7it/s 44.9s\n",
            "                   all       2390       3598      0.826      0.744      0.812       0.56      0.834      0.716      0.792      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      5.42G     0.8776     0.9744     0.7291      1.161         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.1it/s 3:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.7it/s 43.6s\n",
            "                   all       2390       3598      0.835      0.745      0.816      0.561      0.836      0.725        0.8      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      5.62G     0.8784     0.9972     0.7225      1.156         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.7it/s 44.2s\n",
            "                   all       2390       3598       0.85       0.72      0.804      0.558       0.84      0.709      0.786      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      5.44G     0.8735     0.9679      0.729      1.159         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.6it/s 45.8s\n",
            "                   all       2390       3598      0.852      0.746      0.829      0.572       0.85      0.729      0.812      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      5.52G     0.8613     0.9334     0.7137      1.151         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.7it/s 45.2s\n",
            "                   all       2390       3598      0.859      0.754      0.829      0.578      0.854      0.726      0.806      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      5.44G     0.8549      0.925     0.7014      1.151         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8it/s 42.4s\n",
            "                   all       2390       3598      0.841      0.761      0.824      0.576      0.833      0.746      0.808      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100       5.4G     0.8673     0.9547      0.716      1.152         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 461/461 2.0it/s 3:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.5it/s 49.1s\n",
            "                   all       2390       3598      0.878      0.733      0.828      0.575      0.861      0.719      0.804      0.525\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "12 epochs completed in 0.914 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/last.pt, 20.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt, 20.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt...\n",
            "Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s-seg summary (fused): 113 layers, 10,068,364 parameters, 0 gradients, 32.8 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.4it/s 52.7s\n",
            "                   all       2390       3598      0.892      0.758      0.845      0.596      0.883      0.747      0.827       0.55\n",
            "                person        177        346      0.865      0.879      0.921      0.789      0.867      0.873      0.914      0.738\n",
            "                 phone        579        728      0.916      0.762      0.853      0.629      0.906      0.751      0.836       0.59\n",
            "              material       1049       1938      0.825      0.634      0.744       0.57      0.811      0.618      0.718      0.508\n",
            "            headphones        467        586      0.962      0.758       0.86      0.395      0.948      0.744       0.84      0.364\n",
            "Speed: 0.2ms preprocess, 5.7ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load best.pt from previous run for Transfer Learning\n",
        "model = YOLO('/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt')\n",
        "\n",
        "# Train with new classes (Headphones, Material, etc.)\n",
        "results = model.train(\n",
        "    data='/content/merged_dataset/data.yaml',\n",
        "    epochs=100, # Train for 100 more epochs\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    device=0,\n",
        "    project='/content/drive/MyDrive/Intelligence-Test-Models',\n",
        "    name='anticheat_objects_v2_headphones', # New version name\n",
        "    exist_ok=True,\n",
        "    patience=10\n",
        ")"
      ],
      "id": "Ntx3AoCsMgyk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}