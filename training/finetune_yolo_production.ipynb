{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ YOLO Anti-Cheat Model - Production Training\n",
        "\n",
        "**PRODUCTION-READY** notebook v·ªõi datasets ch·∫•t l∆∞·ª£ng cao t·ª´ COCO v√† Roboflow.\n",
        "\n",
        "## üìã H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:\n",
        "1. M·ªü notebook n√†y tr√™n Google Colab\n",
        "2. Ch·ªçn Runtime > Change runtime type > T4 GPU\n",
        "3. B·∫•m **Runtime > Run all** (Ctrl+F9)\n",
        "4. ƒê·ª£i training ho√†n t·∫•t (~2-3 gi·ªù)\n",
        "5. Download file ONNX t·ª´ Google Drive\n",
        "\n",
        "## üéØ Target Classes:\n",
        "- üì± **Phone** - ƒêi·ªán tho·∫°i nhi·ªÅu g√≥c ƒë·ªô (c·∫ßm tay, ƒë·ªÉ b√†n, gi·∫•u)\n",
        "- üìÑ **Material** - T√†i li·ªáu, s√°ch, v·ªü, gi·∫•y gian l·∫≠n\n",
        "- üë§ **Person** - Ph√°t hi·ªán nhi·ªÅu ng∆∞·ªùi trong khung h√¨nh\n",
        "- üéß **Headphones** - Tai nghe (AirPods, earbuds, headset)\n",
        "\n",
        "## üìä Datasets:\n",
        "- **COCO 2017** - Person detection (ch·∫•t l∆∞·ª£ng cao)\n",
        "- **Open Images** - Phone, Book detection\n",
        "- **Roboflow Universe** - Specialized datasets"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 1: Mount Google Drive\n",
        "# ===================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted!\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 2: Install Dependencies\n",
        "# ===================================================\n",
        "!pip install ultralytics==8.3.0 -q\n",
        "!pip install onnx onnxruntime onnxslim -q\n",
        "!pip install fiftyone -q\n",
        "!pip install roboflow -q\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 3: Configuration\n",
        "# ===================================================\n",
        "\n",
        "# Target classes for anti-cheat detection\n",
        "TARGET_CLASSES = ['person', 'phone', 'material', 'headphones']\n",
        "TARGET_CLASS_TO_ID = {c: i for i, c in enumerate(TARGET_CLASSES)}\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = '/content/anticheat_dataset'\n",
        "DRIVE_OUTPUT = '/content/drive/MyDrive/SmartExamPro-Models'\n",
        "\n",
        "# Class mapping from various dataset labels to our target classes\n",
        "CLASS_MAPPING = {\n",
        "    # === PERSON ===\n",
        "    'person': 'person',\n",
        "    'human': 'person',\n",
        "    'people': 'person',\n",
        "    'man': 'person',\n",
        "    'woman': 'person',\n",
        "    'student': 'person',\n",
        "    'face': 'person',\n",
        "    'head': 'person',\n",
        "    'pedestrian': 'person',\n",
        "    \n",
        "    # === PHONE ===\n",
        "    'phone': 'phone',\n",
        "    'cell phone': 'phone',\n",
        "    'cellphone': 'phone',\n",
        "    'mobile phone': 'phone',\n",
        "    'mobile': 'phone',\n",
        "    'smartphone': 'phone',\n",
        "    'iphone': 'phone',\n",
        "    'android': 'phone',\n",
        "    'telephone': 'phone',\n",
        "    'handheld': 'phone',\n",
        "    \n",
        "    # === MATERIAL (books, papers, documents) ===\n",
        "    'book': 'material',\n",
        "    'books': 'material',\n",
        "    'paper': 'material',\n",
        "    'papers': 'material',\n",
        "    'document': 'material',\n",
        "    'notebook': 'material',\n",
        "    'note': 'material',\n",
        "    'notes': 'material',\n",
        "    'sheet': 'material',\n",
        "    'magazine': 'material',\n",
        "    'newspaper': 'material',\n",
        "    'textbook': 'material',\n",
        "    'letter': 'material',\n",
        "    'card': 'material',\n",
        "    'page': 'material',\n",
        "    'cheat sheet': 'material',\n",
        "    \n",
        "    # === HEADPHONES ===\n",
        "    'headphones': 'headphones',\n",
        "    'headphone': 'headphones',\n",
        "    'earphones': 'headphones',\n",
        "    'earphone': 'headphones',\n",
        "    'earbuds': 'headphones',\n",
        "    'earbud': 'headphones',\n",
        "    'airpods': 'headphones',\n",
        "    'airpod': 'headphones',\n",
        "    'headset': 'headphones',\n",
        "    'ear device': 'headphones',\n",
        "    'bluetooth headphones': 'headphones',\n",
        "    'wireless earbuds': 'headphones',\n",
        "}\n",
        "\n",
        "def normalize_class(class_name):\n",
        "    \"\"\"Map any class name to our target class ID\"\"\"\n",
        "    name = class_name.lower().strip().replace('_', ' ').replace('-', ' ')\n",
        "    \n",
        "    # Direct match\n",
        "    if name in CLASS_MAPPING:\n",
        "        return TARGET_CLASS_TO_ID[CLASS_MAPPING[name]]\n",
        "    \n",
        "    # Partial match\n",
        "    for key, target in CLASS_MAPPING.items():\n",
        "        if key in name or name in key:\n",
        "            return TARGET_CLASS_TO_ID[target]\n",
        "    \n",
        "    return -1  # Unknown class\n",
        "\n",
        "def bbox_to_polygon(bbox):\n",
        "    \"\"\"Convert YOLO bbox to segmentation polygon format\"\"\"\n",
        "    try:\n",
        "        xc, yc, w, h = map(float, bbox)\n",
        "        if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
        "            return None\n",
        "        x1, y1 = max(0, xc - w/2), max(0, yc - h/2)\n",
        "        x2, y2 = min(1, xc + w/2), min(1, yc + h/2)\n",
        "        return f\"{x1} {y1} {x2} {y1} {x2} {y2} {x1} {y2}\"\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"Target classes: {TARGET_CLASSES}\")"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 4: Download COCO Dataset (Person class)\n",
        "# ===================================================\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "print(\"üì• Downloading COCO 2017 dataset (person class only)...\")\n",
        "print(\"This may take 10-15 minutes...\")\n",
        "\n",
        "# Download COCO with only person class\n",
        "coco_dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=[\"person\"],\n",
        "    max_samples=5000,  # Limit samples for faster training\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ COCO loaded: {len(coco_dataset)} samples with person class\")"
      ],
      "metadata": {
        "id": "download_coco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 5: Download Open Images Dataset (Phone, Book)\n",
        "# ===================================================\n",
        "\n",
        "print(\"üì• Downloading Open Images V7 (phone, book classes)...\")\n",
        "\n",
        "# Download phone and book from Open Images\n",
        "oi_phone = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=[\"Mobile phone\"],\n",
        "    max_samples=3000,\n",
        ")\n",
        "\n",
        "oi_book = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=[\"Book\"],\n",
        "    max_samples=2000,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Open Images Phone: {len(oi_phone)} samples\")\n",
        "print(f\"‚úÖ Open Images Book: {len(oi_book)} samples\")"
      ],
      "metadata": {
        "id": "download_openimages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 6: Download Roboflow Datasets (Headphones, etc.)\n",
        "# ===================================================\n",
        "from roboflow import Roboflow\n",
        "\n",
        "!mkdir -p /content/roboflow_datasets\n",
        "%cd /content/roboflow_datasets\n",
        "\n",
        "# Roboflow datasets with direct download URLs\n",
        "ROBOFLOW_DATASETS = [\n",
        "    # Headphones/Earphones datasets\n",
        "    (\"earphone_detection\", \"https://app.roboflow.com/ds/qqqEeSKAlk?key=GT1Xa65onI\"),\n",
        "    (\"earphone_v2\", \"https://app.roboflow.com/ds/cKHwOqmuda?key=qL10KsWlBt\"),\n",
        "    \n",
        "    # Phone datasets (various angles)\n",
        "    (\"phone_detection\", \"https://app.roboflow.com/ds/5ReObgnLbQ?key=HTPSgVzDLW\"),\n",
        "    (\"phone_v2\", \"https://app.roboflow.com/ds/f9k54F7Azq?key=eYssUekSYc\"),\n",
        "    \n",
        "    # Paper/Document datasets\n",
        "    (\"document_detection\", \"https://app.roboflow.com/ds/inuabMtp6t?key=jbu7HTlrBf\"),\n",
        "    (\"paper_detection\", \"https://app.roboflow.com/ds/b4oxAhlW40?key=4A761Kjm5F\"),\n",
        "]\n",
        "\n",
        "successful_datasets = []\n",
        "for name, url in ROBOFLOW_DATASETS:\n",
        "    print(f\"üì• Downloading {name}...\")\n",
        "    try:\n",
        "        os.makedirs(name, exist_ok=True)\n",
        "        !curl -L \"{url}\" -o {name}/roboflow.zip 2>/dev/null\n",
        "        if os.path.exists(f\"{name}/roboflow.zip\") and os.path.getsize(f\"{name}/roboflow.zip\") > 1000:\n",
        "            !unzip -q -o {name}/roboflow.zip -d {name}\n",
        "            !rm -f {name}/roboflow.zip\n",
        "            successful_datasets.append(name)\n",
        "            print(f\"   ‚úÖ {name} downloaded\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è {name} failed - skipping\")\n",
        "            !rm -rf {name}\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è {name} error: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Successfully downloaded: {len(successful_datasets)} Roboflow datasets\")"
      ],
      "metadata": {
        "id": "download_roboflow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 7: Prepare Merged Dataset\n",
        "# ===================================================\n",
        "\n",
        "# Create output directories\n",
        "!rm -rf {OUTPUT_DIR}\n",
        "os.makedirs(f\"{OUTPUT_DIR}/train/images\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/train/labels\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/valid/images\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/valid/labels\", exist_ok=True)\n",
        "\n",
        "stats = {'train': 0, 'valid': 0, 'total_labels': 0}\n",
        "class_counts = {c: 0 for c in TARGET_CLASSES}\n",
        "\n",
        "# ===== Process COCO Person =====\n",
        "print(\"\\nüì¶ Processing COCO Person dataset...\")\n",
        "for sample in coco_dataset:\n",
        "    if sample.ground_truth is None:\n",
        "        continue\n",
        "    \n",
        "    img_path = sample.filepath\n",
        "    img_name = os.path.basename(img_path)\n",
        "    split = 'train' if np.random.random() > 0.1 else 'valid'\n",
        "    \n",
        "    # Copy image\n",
        "    dst_img = f\"{OUTPUT_DIR}/{split}/images/coco_{img_name}\"\n",
        "    shutil.copy(img_path, dst_img)\n",
        "    \n",
        "    # Create label\n",
        "    lbl_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "    dst_lbl = f\"{OUTPUT_DIR}/{split}/labels/coco_{lbl_name}\"\n",
        "    \n",
        "    lines = []\n",
        "    for det in sample.ground_truth.detections:\n",
        "        if det.label.lower() == 'person':\n",
        "            x, y, w, h = det.bounding_box  # FiftyOne format\n",
        "            xc, yc = x + w/2, y + h/2\n",
        "            polygon = bbox_to_polygon([xc, yc, w, h])\n",
        "            if polygon:\n",
        "                lines.append(f\"0 {polygon}\")  # 0 = person\n",
        "                class_counts['person'] += 1\n",
        "    \n",
        "    if lines:\n",
        "        with open(dst_lbl, 'w') as f:\n",
        "            f.write('\\n'.join(lines))\n",
        "        stats[split] += 1\n",
        "        stats['total_labels'] += len(lines)\n",
        "\n",
        "print(f\"   Processed {stats['train'] + stats['valid']} COCO images\")\n",
        "\n",
        "# ===== Process Open Images Phone =====\n",
        "print(\"\\nüì¶ Processing Open Images Phone...\")\n",
        "count = 0\n",
        "for sample in oi_phone:\n",
        "    if sample.ground_truth is None:\n",
        "        continue\n",
        "    \n",
        "    img_path = sample.filepath\n",
        "    img_name = os.path.basename(img_path)\n",
        "    split = 'train' if np.random.random() > 0.1 else 'valid'\n",
        "    \n",
        "    dst_img = f\"{OUTPUT_DIR}/{split}/images/oi_phone_{img_name}\"\n",
        "    shutil.copy(img_path, dst_img)\n",
        "    \n",
        "    lbl_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "    dst_lbl = f\"{OUTPUT_DIR}/{split}/labels/oi_phone_{lbl_name}\"\n",
        "    \n",
        "    lines = []\n",
        "    for det in sample.ground_truth.detections:\n",
        "        x, y, w, h = det.bounding_box\n",
        "        xc, yc = x + w/2, y + h/2\n",
        "        polygon = bbox_to_polygon([xc, yc, w, h])\n",
        "        if polygon:\n",
        "            lines.append(f\"1 {polygon}\")  # 1 = phone\n",
        "            class_counts['phone'] += 1\n",
        "    \n",
        "    if lines:\n",
        "        with open(dst_lbl, 'w') as f:\n",
        "            f.write('\\n'.join(lines))\n",
        "        stats[split] += 1\n",
        "        stats['total_labels'] += len(lines)\n",
        "        count += 1\n",
        "\n",
        "print(f\"   Processed {count} phone images\")\n",
        "\n",
        "# ===== Process Open Images Book =====\n",
        "print(\"\\nüì¶ Processing Open Images Book...\")\n",
        "count = 0\n",
        "for sample in oi_book:\n",
        "    if sample.ground_truth is None:\n",
        "        continue\n",
        "    \n",
        "    img_path = sample.filepath\n",
        "    img_name = os.path.basename(img_path)\n",
        "    split = 'train' if np.random.random() > 0.1 else 'valid'\n",
        "    \n",
        "    dst_img = f\"{OUTPUT_DIR}/{split}/images/oi_book_{img_name}\"\n",
        "    shutil.copy(img_path, dst_img)\n",
        "    \n",
        "    lbl_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "    dst_lbl = f\"{OUTPUT_DIR}/{split}/labels/oi_book_{lbl_name}\"\n",
        "    \n",
        "    lines = []\n",
        "    for det in sample.ground_truth.detections:\n",
        "        x, y, w, h = det.bounding_box\n",
        "        xc, yc = x + w/2, y + h/2\n",
        "        polygon = bbox_to_polygon([xc, yc, w, h])\n",
        "        if polygon:\n",
        "            lines.append(f\"2 {polygon}\")  # 2 = material\n",
        "            class_counts['material'] += 1\n",
        "    \n",
        "    if lines:\n",
        "        with open(dst_lbl, 'w') as f:\n",
        "            f.write('\\n'.join(lines))\n",
        "        stats[split] += 1\n",
        "        stats['total_labels'] += len(lines)\n",
        "        count += 1\n",
        "\n",
        "print(f\"   Processed {count} book images\")"
      ],
      "metadata": {
        "id": "prepare_coco_oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 8: Process Roboflow Datasets\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\nüì¶ Processing Roboflow datasets...\")\n",
        "\n",
        "for dataset_name in successful_datasets:\n",
        "    dataset_dir = f\"/content/roboflow_datasets/{dataset_name}\"\n",
        "    \n",
        "    # Find data.yaml\n",
        "    data_yaml = None\n",
        "    for root, dirs, files in os.walk(dataset_dir):\n",
        "        if 'data.yaml' in files:\n",
        "            data_yaml = os.path.join(root, 'data.yaml')\n",
        "            break\n",
        "    \n",
        "    if not data_yaml:\n",
        "        print(f\"   ‚ö†Ô∏è No data.yaml in {dataset_name}\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        with open(data_yaml, 'r') as f:\n",
        "            config = yaml.safe_load(f)\n",
        "    except:\n",
        "        print(f\"   ‚ö†Ô∏è Cannot parse data.yaml in {dataset_name}\")\n",
        "        continue\n",
        "    \n",
        "    source_classes = config.get('names', [])\n",
        "    if isinstance(source_classes, dict):\n",
        "        source_classes = list(source_classes.values())\n",
        "    \n",
        "    print(f\"   Processing {dataset_name} (classes: {source_classes})...\")\n",
        "    \n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        img_dir = None\n",
        "        lbl_dir = None\n",
        "        \n",
        "        for try_path in [dataset_dir, os.path.dirname(data_yaml)]:\n",
        "            if os.path.exists(os.path.join(try_path, split, 'images')):\n",
        "                img_dir = os.path.join(try_path, split, 'images')\n",
        "                lbl_dir = os.path.join(try_path, split, 'labels')\n",
        "                break\n",
        "        \n",
        "        if not img_dir or not os.path.exists(img_dir):\n",
        "            continue\n",
        "        \n",
        "        out_split = 'train' if split in ['train', 'test'] else 'valid'\n",
        "        count = 0\n",
        "        \n",
        "        for img_file in os.listdir(img_dir):\n",
        "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "            \n",
        "            src_img = os.path.join(img_dir, img_file)\n",
        "            dst_img = f\"{OUTPUT_DIR}/{out_split}/images/rb_{dataset_name}_{img_file}\"\n",
        "            shutil.copy(src_img, dst_img)\n",
        "            \n",
        "            lbl_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "            src_lbl = os.path.join(lbl_dir, lbl_file)\n",
        "            dst_lbl = f\"{OUTPUT_DIR}/{out_split}/labels/rb_{dataset_name}_{lbl_file}\"\n",
        "            \n",
        "            if os.path.exists(src_lbl):\n",
        "                with open(src_lbl, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "                \n",
        "                new_lines = []\n",
        "                for line in lines:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) < 5:\n",
        "                        continue\n",
        "                    \n",
        "                    try:\n",
        "                        old_class_id = int(parts[0])\n",
        "                        if old_class_id >= len(source_classes):\n",
        "                            continue\n",
        "                        \n",
        "                        old_class_name = source_classes[old_class_id]\n",
        "                        new_class_id = normalize_class(old_class_name)\n",
        "                        \n",
        "                        if new_class_id >= 0:\n",
        "                            class_counts[TARGET_CLASSES[new_class_id]] += 1\n",
        "                            \n",
        "                            if len(parts) == 5:  # bbox format\n",
        "                                polygon = bbox_to_polygon(parts[1:])\n",
        "                                if polygon:\n",
        "                                    new_lines.append(f\"{new_class_id} {polygon}\")\n",
        "                            elif len(parts) >= 9:  # already segmentation\n",
        "                                new_lines.append(f\"{new_class_id} {' '.join(parts[1:])}\")\n",
        "                    except:\n",
        "                        continue\n",
        "                \n",
        "                if new_lines:\n",
        "                    with open(dst_lbl, 'w') as f:\n",
        "                        f.write('\\n'.join(new_lines))\n",
        "                    stats[out_split] += 1\n",
        "                    stats['total_labels'] += len(new_lines)\n",
        "                    count += 1\n",
        "        \n",
        "        if count > 0:\n",
        "            print(f\"      {split}: {count} images\")\n",
        "\n",
        "# Create data.yaml\n",
        "data_config = {\n",
        "    'path': OUTPUT_DIR,\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'names': {i: name for i, name in enumerate(TARGET_CLASSES)},\n",
        "    'nc': len(TARGET_CLASSES),\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/data.yaml\", 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä DATASET SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Train images: {stats['train']}\")\n",
        "print(f\"Valid images: {stats['valid']}\")\n",
        "print(f\"Total labels: {stats['total_labels']}\")\n",
        "print(\"\\nClass distribution:\")\n",
        "for cls, count in class_counts.items():\n",
        "    print(f\"   {cls}: {count}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "process_roboflow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 9: Train YOLO Model\n",
        "# ===================================================\n",
        "\n",
        "# Choose base model\n",
        "# Options: yolo11n-seg.pt (fast), yolo11s-seg.pt (balanced), yolo11m-seg.pt (accurate)\n",
        "BASE_MODEL = 'yolo11s-seg.pt'\n",
        "\n",
        "print(f\"üöÄ Starting training with {BASE_MODEL}...\")\n",
        "print(\"This will take approximately 2-3 hours on T4 GPU\")\n",
        "\n",
        "# Create output directory on Drive\n",
        "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
        "\n",
        "model = YOLO(BASE_MODEL)\n",
        "\n",
        "results = model.train(\n",
        "    data=f\"{OUTPUT_DIR}/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,  # Reduce if OOM\n",
        "    patience=20,\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    warmup_epochs=5,\n",
        "    augment=True,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.1,\n",
        "    copy_paste=0.1,\n",
        "    degrees=10,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    shear=2.0,\n",
        "    perspective=0.0001,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    project=DRIVE_OUTPUT,\n",
        "    name='anticheat_production',\n",
        "    exist_ok=True,\n",
        "    device=0,\n",
        "    verbose=True,\n",
        "    save=True,\n",
        "    plots=True,\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Training completed!\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 10: Validate Model\n",
        "# ===================================================\n",
        "\n",
        "BEST_MODEL = f\"{DRIVE_OUTPUT}/anticheat_production/weights/best.pt\"\n",
        "\n",
        "print(\"üìä Validating model...\")\n",
        "model = YOLO(BEST_MODEL)\n",
        "metrics = model.val(data=f\"{OUTPUT_DIR}/data.yaml\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä VALIDATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Overall mAP50: {metrics.box.map50:.3f}\")\n",
        "print(f\"Overall mAP50-95: {metrics.box.map:.3f}\")\n",
        "print(\"\\nPer-class mAP50:\")\n",
        "for i, cls in enumerate(TARGET_CLASSES):\n",
        "    if i < len(metrics.box.ap50):\n",
        "        print(f\"   {cls}: {metrics.box.ap50[i]:.3f}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "validate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 11: Export to ONNX\n",
        "# ===================================================\n",
        "\n",
        "print(\"üì¶ Exporting to ONNX format...\")\n",
        "\n",
        "model = YOLO(BEST_MODEL)\n",
        "\n",
        "# Export with optimizations for web deployment\n",
        "model.export(\n",
        "    format='onnx',\n",
        "    imgsz=640,\n",
        "    simplify=True,\n",
        "    dynamic=False,\n",
        "    opset=17,\n",
        ")\n",
        "\n",
        "ONNX_PATH = BEST_MODEL.replace('.pt', '.onnx')\n",
        "\n",
        "# Also save to a standard location\n",
        "FINAL_ONNX = f\"{DRIVE_OUTPUT}/anticheat_yolo11s.onnx\"\n",
        "shutil.copy(ONNX_PATH, FINAL_ONNX)\n",
        "\n",
        "print(f\"\\n‚úÖ ONNX model saved to:\")\n",
        "print(f\"   {FINAL_ONNX}\")\n",
        "print(f\"\\nFile size: {os.path.getsize(FINAL_ONNX) / 1024 / 1024:.1f} MB\")"
      ],
      "metadata": {
        "id": "export"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 12: Test Model on Sample Images\n",
        "# ===================================================\n",
        "import onnxruntime as ort\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "print(\"üß™ Testing ONNX model...\")\n",
        "\n",
        "session = ort.InferenceSession(FINAL_ONNX)\n",
        "input_name = session.get_inputs()[0].name\n",
        "\n",
        "# Get a test image from validation set\n",
        "valid_imgs = os.listdir(f\"{OUTPUT_DIR}/valid/images\")\n",
        "if valid_imgs:\n",
        "    test_img_path = f\"{OUTPUT_DIR}/valid/images/{valid_imgs[0]}\"\n",
        "    img = Image.open(test_img_path).convert('RGB').resize((640, 640))\n",
        "    img_array = np.array(img).astype(np.float32) / 255.0\n",
        "    img_array = np.transpose(img_array, (2, 0, 1))\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    \n",
        "    outputs = session.run(None, {input_name: img_array})\n",
        "    \n",
        "    print(\"\\nModel output shape:\", outputs[0].shape)\n",
        "    print(\"\\nMax confidence per class:\")\n",
        "    class_scores = outputs[0][0, 4:8, :]\n",
        "    for i, cls in enumerate(TARGET_CLASSES):\n",
        "        print(f\"   {cls}: {class_scores[i].max():.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ Model test passed!\")"
      ],
      "metadata": {
        "id": "test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# CELL 13: Final Instructions\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ TRAINING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüì• DOWNLOAD & DEPLOY:\")\n",
        "print(f\"\\n1. Download ONNX file from Google Drive:\")\n",
        "print(f\"   {FINAL_ONNX}\")\n",
        "print(f\"\\n2. Rename to: anticheat_yolo11s.onnx\")\n",
        "print(f\"\\n3. Copy to your project:\")\n",
        "print(f\"   Intelligence-Test/public/models/anticheat_yolo11s.onnx\")\n",
        "print(f\"\\n4. Rebuild and deploy:\")\n",
        "print(f\"   cd Intelligence-Test && npm run build\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nüìä Model files saved in Google Drive:\")\n",
        "print(f\"   {DRIVE_OUTPUT}/\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ anticheat_production/\")\n",
        "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ weights/best.pt\")\n",
        "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ weights/best.onnx\")\n",
        "print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ results.png\")\n",
        "print(\"   ‚îî‚îÄ‚îÄ anticheat_yolo11s.onnx\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "finish"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
