{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48wkMoJzMgyb"
      },
      "source": [
        "## 1. C√†i ƒë·∫∑t & Fix L·ªói"
      ],
      "id": "48wkMoJzMgyb"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6qB10l4Rvq4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7cf5b9-c6b2-4e0c-92c1-5c13dc0ff2c1"
      },
      "id": "6qB10l4Rvq4c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQNploZWMgyd",
        "outputId": "08bea34e-f0e6-4c40-e0b3-c0a3eb8f15b8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.237)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "N·∫øu c√≥ n√∫t Restart Session, h√£y b·∫•m n√≥\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install ultralytics kaggle\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "import cv2\n",
        "import random\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "\n",
        "print(\"N·∫øu c√≥ n√∫t Restart Session, h√£y b·∫•m n√≥\")"
      ],
      "id": "NQNploZWMgyd"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfmhgeANyR7a"
      },
      "id": "SfmhgeANyR7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdWsQb8fMgyf"
      },
      "source": [
        "## 2. T·∫£i Dataset (Roboflow + MUID-IITR)"
      ],
      "id": "vdWsQb8fMgyf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iDIlf6lWMgyf",
        "outputId": "8360f414-3b1a-4b27-c07b-51ecee56512b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/raw_datasets\n",
            "ƒêang t·∫£i ds_headphones_3...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   2741      0 --:--:-- --:--:-- --:--:--  2739\n",
            "100  896k  100  896k    0     0   988k      0 --:--:-- --:--:-- --:--:--  988k\n",
            "ƒêang t·∫£i ds_headphones_4...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   2850      0 --:--:-- --:--:-- --:--:--  2851\n",
            "100 88.8M  100 88.8M    0     0  36.5M      0  0:00:02  0:00:02 --:--:-- 57.0M\n",
            "ƒêang t·∫£i ds_headphones_5...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   3860      0 --:--:-- --:--:-- --:--:--  3863\n",
            "100 91.4M  100 91.4M    0     0  45.9M      0  0:00:01  0:00:01 --:--:-- 70.1M\n",
            "ƒêang t·∫£i ds_paper1...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   3560      0 --:--:-- --:--:-- --:--:--  3559\n",
            "100  276M  100  276M    0     0  62.1M      0  0:00:04  0:00:04 --:--:-- 78.0M\n",
            "ƒêang t·∫£i ds_paper2...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   3828      0 --:--:-- --:--:-- --:--:--  3814\n",
            "100 3447k  100 3447k    0     0  4009k      0 --:--:-- --:--:-- --:--:-- 4009k\n",
            "ƒêang t·∫£i ds_phone...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   2861      0 --:--:-- --:--:-- --:--:--  2860\n",
            "100 26.6M  100 26.6M    0     0  21.1M      0  0:00:01  0:00:01 --:--:-- 57.3M\n",
            "ƒêang t·∫£i ds_phone2...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   4094      0 --:--:-- --:--:-- --:--:--  4090\n",
            "100 46.9M  100 46.9M    0     0  26.5M      0  0:00:01  0:00:01 --:--:-- 47.8M\n",
            "ƒêang t·∫£i ds_person...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   904  100   904    0     0   3761      0 --:--:-- --:--:-- --:--:--  3766\n",
            "100  677k  100  677k    0     0   816k      0 --:--:-- --:--:-- --:--:-- 6647k\n",
            "\n",
            "--- C·∫§U H√åNH KAGGLE ƒê·ªÇ T·∫¢I DATASET 'B·∫†CH KIM' (MUID-IITR) ---\n",
            "‚ö†Ô∏è Ch∆∞a th·∫•y file kaggle.json. Vui l√≤ng upload file kaggle.json ngay b√¢y gi·ªù:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3aacd6b7-c608-4603-84bf-b2db15a08c56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3aacd6b7-c608-4603-84bf-b2db15a08c56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ƒê√£ nh·∫≠n file \"kaggle.json\" v·ªõi k√≠ch th∆∞·ªõc 68 bytes\n",
            "‚úÖ ƒê√£ x√°c th·ª±c Kaggle th√†nh c√¥ng!\n",
            "ƒêang t·∫£i MUID-IITR Dataset (Platinum) v·ªõi ID m·ªõi...\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshyataragi/mobilephoneusagedatasetiitr\n",
            "License(s): unknown\n",
            "Downloading mobilephoneusagedatasetiitr.zip to /content/raw_datasets/muid\n",
            " 96% 583M/610M [00:03<00:00, 70.2MB/s]\n",
            "100% 610M/610M [00:03<00:00, 181MB/s] \n",
            "ƒêang gi·∫£i n√©n /content/raw_datasets/muid/mobilephoneusagedatasetiitr.zip...\n",
            "‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n MUID-IITR th√†nh c√¥ng!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil # Th√™m import shutil n·∫øu ch∆∞a c√≥\n",
        "from google.colab import files # Th√™m import files n·∫øu ch∆∞a c√≥\n",
        "\n",
        "!mkdir -p /content/raw_datasets\n",
        "%cd /content/raw_datasets\n",
        "\n",
        "# 1. T·∫£i Roboflow Datasets (C∆° b·∫£n)\n",
        "datasets_links = [\n",
        "    # --- USER PROVIDED DATASETS ---\n",
        "    (\"ds_headphones_3\", \"https://app.roboflow.com/ds/qqqEeSKAlk?key=GT1Xa65onI\"), # Headphones 3\n",
        "    (\"ds_headphones_4\", \"https://app.roboflow.com/ds/cKHwOqmuda?key=qL10KsWlBt\"), # Headphones 4\n",
        "    (\"ds_headphones_5\", \"https://app.roboflow.com/ds/Ailn10pxiU?key=hBaHIe4EfQ\"),\n",
        "\n",
        "\n",
        "    (\"ds_paper1\", \"https://app.roboflow.com/ds/inuabMtp6t?key=jbu7HTlrBf\"),       #Paper1\n",
        "    (\"ds_paper2\", \"https://app.roboflow.com/ds/b4oxAhlW40?key=4A761Kjm5F\"),\n",
        "\n",
        "    (\"ds_phone\", \"https://app.roboflow.com/ds/5ReObgnLbQ?key=HTPSgVzDLW\"),        # Phone\n",
        "    (\"ds_phone2\", \"https://app.roboflow.com/ds/f9k54F7Azq?key=eYssUekSYc\"),       # Phone 2\n",
        "\n",
        "    (\"ds_person\", \"https://app.roboflow.com/ds/PwRwV0c1jL?key=FgXbXeqlpH\"),       # Person\n",
        "]\n",
        "\n",
        "for name, url in datasets_links:\n",
        "    if not os.path.exists(name):\n",
        "        print(f\"ƒêang t·∫£i {name}...\")\n",
        "        !mkdir -p {name}\n",
        "        !curl -L \"{url}\" > {name}/dataset.zip\n",
        "        !unzip -q {name}/dataset.zip -d {name}\n",
        "        !rm {name}/dataset.zip\n",
        "\n",
        "# 2. T·∫£i Dataset N√¢ng Cao t·ª´ Kaggle (MUID-IITR)\n",
        "print(\"\\n--- C·∫§U H√åNH KAGGLE ƒê·ªÇ T·∫¢I DATASET 'B·∫†CH KIM' (MUID-IITR) ---\")\n",
        "\n",
        "if not os.path.exists(\"/root/.kaggle\"):\n",
        "    !mkdir -p /root/.kaggle\n",
        "\n",
        "if not os.path.exists(\"/content/kaggle.json\"):\n",
        "    print(\"‚ö†Ô∏è Ch∆∞a th·∫•y file kaggle.json. Vui l√≤ng upload file kaggle.json ngay b√¢y gi·ªù:\")\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        print(f'ƒê√£ nh·∫≠n file \"{fn}\" v·ªõi k√≠ch th∆∞·ªõc {len(uploaded[fn])} bytes')\n",
        "        !mv {fn} /content/kaggle.json\n",
        "\n",
        "if os.path.exists(\"/content/kaggle.json\"):\n",
        "    !cp /content/kaggle.json /root/.kaggle/\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "    print(\"‚úÖ ƒê√£ x√°c th·ª±c Kaggle th√†nh c√¥ng!\")\n",
        "\n",
        "    # T·∫£i MUID-IITR (Platinum - Phone Specialist) v·ªõi ID m·ªõi\n",
        "    print(\"ƒêang t·∫£i MUID-IITR Dataset (Platinum) v·ªõi ID m·ªõi...\")\n",
        "    muid_target_dir = \"/content/raw_datasets/muid\"\n",
        "    os.makedirs(muid_target_dir, exist_ok=True)\n",
        "    !kaggle datasets download lakshyataragi/mobilephoneusagedatasetiitr -p {muid_target_dir}\n",
        "\n",
        "    # Gi·∫£i n√©n dataset\n",
        "    zip_file_path = os.path.join(muid_target_dir, \"mobilephoneusagedatasetiitr.zip\")\n",
        "    if os.path.exists(zip_file_path):\n",
        "        print(f\"ƒêang gi·∫£i n√©n {zip_file_path}...\")\n",
        "        !unzip -q {zip_file_path} -d {muid_target_dir}\n",
        "        # X√≥a file zip sau khi gi·∫£i n√©n ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng\n",
        "        os.remove(zip_file_path)\n",
        "        print(\"‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n MUID-IITR th√†nh c√¥ng!\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file {zip_file_path} sau khi t·∫£i. Vui l√≤ng ki·ªÉm tra l·∫°i ID dataset ho·∫∑c quy·ªÅn truy c·∫≠p.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è KH√îNG C√ì TH√îNG TIN KAGGLE. S·∫Ω b·ªè qua MUID, ch·ªâ d√πng Roboflow.\")"
      ],
      "id": "iDIlf6lWMgyf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mj_EtfyMgyg"
      },
      "source": [
        "## 3.  AI Auto-Labeling (Teacher: YOLO11x-seg)\n",
        "D√πng Teacher Model ƒë·ªÉ g√°n nh√£n l·∫°i to√†n b·ªô d·ªØ li·ªáu (bao g·ªìm c·∫£ MUID)."
      ],
      "id": "4mj_EtfyMgyg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGdjIr7dMgyh",
        "outputId": "c1cc933a-53da-4248-e911-7c8f4a93c5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-seg.pt to 'yolo11x-seg.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 119.3MB 114.3MB/s 1.0s\n",
            "ƒêang x·ª≠ l√Ω /content/raw_datasets/ds1...\n",
            "   T·ªïng c·ªông 0 ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ƒêang x·ª≠ l√Ω /content/raw_datasets/muid...\n",
            "   T·ªïng c·ªông 888 ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 888/888 [01:41<00:00,  8.71it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load model Segmentation Teacher\n",
        "auto_label_model = YOLO('yolo11x-seg.pt')\n",
        "\n",
        "def auto_label_dataset(source_path, target_dir, is_video=False):\n",
        "    print(f\"ƒêang x·ª≠ l√Ω {source_path}...\")\n",
        "    images = []\n",
        "\n",
        "    for root, dirs, files in os.walk(source_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                images.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"   T·ªïng c·ªông {len(images)} ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\")\n",
        "\n",
        "    # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c Train/Valid\n",
        "    for split in ['train', 'valid']:\n",
        "        os.makedirs(f\"{target_dir}/{split}/images\", exist_ok=True)\n",
        "        os.makedirs(f\"{target_dir}/{split}/labels\", exist_ok=True)\n",
        "\n",
        "    random.shuffle(images)\n",
        "\n",
        "    for idx, img_path in enumerate(tqdm(images)):\n",
        "        split = 'train' if idx < len(images) * 0.8 else 'valid'\n",
        "\n",
        "        file_name = os.path.basename(img_path)\n",
        "        # Th√™m prefix ƒë·ªÉ tr√°nh tr√πng t√™n\n",
        "        prefix = f\"{os.path.basename(source_path)}_\"\n",
        "        unique_name = f\"{prefix}{file_name}\"\n",
        "\n",
        "        dest_img_path = f\"{target_dir}/{split}/images/{unique_name}\"\n",
        "        shutil.copy(img_path, dest_img_path)\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None: continue\n",
        "\n",
        "        # Run YOLO Segmentation (Teacher)\n",
        "        results = auto_label_model(image, verbose=False, conf=0.4)[0]\n",
        "        label_lines = []\n",
        "\n",
        "        if results.masks:\n",
        "            for i, mask in enumerate(results.masks.xyn):\n",
        "                cls_id = int(results.boxes.cls[i])\n",
        "                # COCO: 0=person, 67=cell phone, 73=book\n",
        "                # TARGET: 0=person, 1=phone, 2=book, 3=paper\n",
        "                my_cls_id = -1\n",
        "\n",
        "                if cls_id == 0:\n",
        "                    my_cls_id = 0 # person\n",
        "                elif cls_id == 67:\n",
        "                    my_cls_id = 1 # phone\n",
        "                elif cls_id == 73:\n",
        "                    my_cls_id = 2 # book\n",
        "\n",
        "                if my_cls_id != -1:\n",
        "                    mask_str = \" \".join(map(str, mask.flatten()))\n",
        "                    label_lines.append(f\"{my_cls_id} {mask_str}\")\n",
        "\n",
        "        if label_lines:\n",
        "            label_name = unique_name.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')\n",
        "            with open(f\"{target_dir}/{split}/labels/{label_name}\", 'w') as f:\n",
        "                f.write('\\n'.join(label_lines))\n",
        "\n",
        "OUTPUT_DIR = \"/content/merged_dataset\"\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "\n",
        "# 1. Auto-label ds1 (Roboflow)\n",
        "auto_label_dataset(\"/content/raw_datasets/ds1\", OUTPUT_DIR, is_video=False)\n",
        "\n",
        "# 2. Auto-label MUID (Platinum) - N·∫øu c√≥\n",
        "if os.path.exists(\"/content/raw_datasets/muid\"):\n",
        "    auto_label_dataset(\"/content/raw_datasets/muid\", OUTPUT_DIR, is_video=False)"
      ],
      "id": "mGdjIr7dMgyh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK5_PJoAMgyi"
      },
      "source": [
        "## 4. Merge c√°c Dataset c√≤n l·∫°i (ds2 - ds6)"
      ],
      "id": "eK5_PJoAMgyi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYbLx-JxMgyj",
        "outputId": "281b2c34-7823-45ad-80ef-4d6469fccd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ƒêang g·ªôp c√°c dataset chu·∫©n (ds2-ds6) v√† chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng segmentation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ds_headphones_3 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:00<00:00, 4359.49it/s]\n",
            "ds_headphones_3 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:00<00:00, 3382.11it/s]\n",
            "ds_headphones_3 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 2582.10it/s]\n",
            "ds_headphones_4 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 364/364 [00:00<00:00, 3253.32it/s]\n",
            "ds_headphones_4 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:00<00:00, 2803.91it/s]\n",
            "ds_headphones_4 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:00<00:00, 1895.73it/s]\n",
            "ds_headphones_5 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 608/608 [00:00<00:00, 2380.98it/s]\n",
            "ds_headphones_5 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 191/191 [00:00<00:00, 3166.26it/s]\n",
            "ds_headphones_5 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [00:00<00:00, 3732.68it/s]\n",
            "ds_paper1 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3459/3459 [00:00<00:00, 3517.43it/s]\n",
            "ds_paper1 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 453/453 [00:00<00:00, 3759.94it/s]\n",
            "ds_paper1 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1174/1174 [00:00<00:00, 3877.29it/s]\n",
            "ds_paper2 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53/53 [00:00<00:00, 4040.83it/s]\n",
            "ds_paper2 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 2750.93it/s]\n",
            "ds_paper2 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 2373.11it/s]\n",
            "ds_phone - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1178/1178 [00:00<00:00, 4158.62it/s]\n",
            "ds_phone - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:00<00:00, 3151.81it/s]\n",
            "ds_phone - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 2725.93it/s]\n",
            "ds_phone2 - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1218/1218 [00:00<00:00, 3780.38it/s]\n",
            "ds_phone2 - valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 4386.06it/s]\n",
            "ds_phone2 - test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [00:00<00:00, 4239.25it/s]\n",
            "ds_person - train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 5389.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " G·ªôp dataset ho√†n t·∫•t! Model n√†y s·∫Ω CHUY√äN TR·ªä V·∫¨T TH·ªÇ (Person, Phone, Book, Paper).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "TARGET_CLASSES = ['person', 'phone', 'material', 'headphones']\n",
        "\n",
        "CLASS_MAPPING = {\n",
        "    'person': 'person', 'student': 'person', 'face': 'person', 'head': 'person',\n",
        "    'phone': 'phone', 'mobile': 'phone', 'cell phone': 'phone', 'telephone': 'phone', 'smartphone': 'phone', 'ProductRecog - v2 2024-11-05 7:03am': 'phone',\n",
        "    'paper': 'material', 'PAPER': 'material', 'Paper': 'material', 'document': 'material',\n",
        "    'headphone': 'headphones', 'headphones': 'headphones', 'earphone': 'headphones', 'headset': 'headphones', 'earbuds': 'headphones', 'Headphone': 'headphones', 'ear device': 'headphones', 'left earbud': 'headphones', 'eardevice': 'headphones'\n",
        "}\n",
        "\n",
        "os.makedirs(f\"{OUTPUT_DIR}/train/images\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/train/labels\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/valid/images\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/valid/labels\", exist_ok=True)\n",
        "\n",
        "def normalize_class(class_name):\n",
        "    class_name = class_name.lower().strip()\n",
        "    for key, target in CLASS_MAPPING.items():\n",
        "        if class_name == key:\n",
        "            if target == 'ignore': return -1\n",
        "            return TARGET_CLASSES.index(target)\n",
        "    return -1\n",
        "\n",
        "def find_data_yaml(start_dir):\n",
        "    for root, dirs, files in os.walk(start_dir):\n",
        "        if 'data.yaml' in files:\n",
        "            return os.path.join(root, 'data.yaml')\n",
        "    return None\n",
        "\n",
        "# Helper function to convert YOLO bounding box (xc yc w h) to segmentation polygon (x1 y1 x2 y2 x3 y3 x4 y4)\n",
        "def bbox_to_segment(bbox_coords):\n",
        "    try:\n",
        "        # bbox_coords is a list of strings: [x_center, y_center, width, height]\n",
        "        # Convert to float\n",
        "        xc, yc, w, h = map(float, bbox_coords)\n",
        "        # Calculate corner points (normalized)\n",
        "        x1, y1 = xc - w/2, yc - h/2  # Top-left\n",
        "        x2, y2 = xc + w/2, yc - h/2  # Top-right\n",
        "        x3, y3 = xc + w/2, yc + h/2  # Bottom-right\n",
        "        x4, y4 = xc - w/2, yc + h/2  # Bottom-left\n",
        "        return f\"{x1} {y1} {x2} {y2} {x3} {y3} {x4} {y4}\"\n",
        "    except ValueError:\n",
        "        return None # Return None if conversion fails\n",
        "\n",
        "good_datasets = datasets_links[0:]\n",
        "\n",
        "print(\"üîÑ ƒêang g·ªôp c√°c dataset chu·∫©n (ds2-ds6) v√† chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng segmentation...\")\n",
        "\n",
        "for ds_name, _ in good_datasets:\n",
        "    ds_path = f\"/content/raw_datasets/{ds_name}\"\n",
        "    yaml_path = find_data_yaml(ds_path)\n",
        "\n",
        "    if not yaml_path:\n",
        "        print(f\"{ds_name}: Kh√¥ng t√¨m th·∫•y data.yaml -> B·ªè qua.\")\n",
        "        continue\n",
        "\n",
        "    ds_root = os.path.dirname(yaml_path)\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    source_classes = data_config.get('names', [])\n",
        "\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        possible_img_dirs = [\n",
        "            os.path.join(ds_root, split, 'images'),\n",
        "            os.path.join(ds_root, split),\n",
        "            os.path.join(ds_path, split, 'images'),\n",
        "            os.path.join(ds_path, split)\n",
        "        ]\n",
        "        src_img_dir = None\n",
        "        for d in possible_img_dirs:\n",
        "            if os.path.exists(d) and (glob(f\"{d}/*.jpg\") or glob(f\"{d}/*.png\")):\n",
        "                src_img_dir = d\n",
        "                break\n",
        "        if not src_img_dir: continue\n",
        "\n",
        "        images = glob(f\"{src_img_dir}/*.jpg\") + glob(f\"{src_img_dir}/*.png\")\n",
        "        target_split = 'valid' if split in ['valid', 'test'] else 'train'\n",
        "\n",
        "        for img_path in tqdm(images, desc=f\"{ds_name} - {split}\"):\n",
        "            file_name = os.path.basename(img_path)\n",
        "            unique_name = f\"{ds_name}_{file_name}\"\n",
        "            shutil.copy(img_path, f\"{OUTPUT_DIR}/{target_split}/images/{unique_name}\")\n",
        "\n",
        "            label_name = file_name.replace('.jpg', '.txt').replace('.png', '.txt')\n",
        "            possible_label_paths = [\n",
        "                img_path.replace('/images/', '/labels/').replace(file_name, label_name),\n",
        "                os.path.join(ds_root, split, 'labels', label_name),\n",
        "                os.path.join(ds_path, split, 'labels', label_name)\n",
        "            ]\n",
        "            label_path = None\n",
        "            for p in possible_label_paths:\n",
        "                if os.path.exists(p):\n",
        "                    label_path = p\n",
        "                    break\n",
        "\n",
        "            if label_path:\n",
        "                new_labels = []\n",
        "                with open(label_path, 'r') as lf:\n",
        "                    for line in lf:\n",
        "                        parts = line.strip().split()\n",
        "                        if not parts: continue\n",
        "                        try:\n",
        "                            cls_id = int(parts[0])\n",
        "                            if cls_id < len(source_classes):\n",
        "                                cls_name = source_classes[cls_id]\n",
        "                                new_id = normalize_class(cls_name)\n",
        "                                if new_id != -1:\n",
        "                                    # Check if the label is a bounding box (5 parts) or segmentation (more than 5 parts)\n",
        "                                    if len(parts) == 5: # Assuming it's a bounding box: class x_c y_c w h\n",
        "                                        segment_coords = bbox_to_segment(parts[1:])\n",
        "                                        if segment_coords:\n",
        "                                            new_labels.append(f\"{new_id} {segment_coords}\")\n",
        "                                    else: # Already segmentation format (class x1 y1 x2 y2 ...)\n",
        "                                        new_labels.append(f\"{new_id} {' '.join(parts[1:])}\")\n",
        "                        except ValueError: continue\n",
        "\n",
        "                with open(f\"{OUTPUT_DIR}/{target_split}/labels/{unique_name.replace('.jpg','.txt').replace('.png','.txt')}\", 'w') as nf:\n",
        "                    nf.write('\\n'.join(new_labels))\n",
        "\n",
        "final_yaml = {\n",
        "    'path': OUTPUT_DIR,\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'nc': len(TARGET_CLASSES),\n",
        "    'names': TARGET_CLASSES\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/data.yaml\", 'w') as f:\n",
        "    yaml.dump(final_yaml, f)\n",
        "\n",
        "print(\"\\n G·ªôp dataset ho√†n t·∫•t! Model n√†y s·∫Ω CHUY√äN TR·ªä V·∫¨T TH·ªÇ (Person, Phone, Book, Paper).\")"
      ],
      "id": "IYbLx-JxMgyj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq379XPDMgyj"
      },
      "source": [
        "## 5. Train Model (Object Expert)"
      ],
      "id": "fq379XPDMgyj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntx3AoCsMgyk",
        "outputId": "4cf87f68-1211-460a-c876-0f8fbb7a9bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.237 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=28, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/merged_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=anticheat_objects_v2_headphones, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Intelligence-Test-Models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 16.6MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1   1475452  ultralytics.nn.modules.head.Segment          [4, 32, 128, [128, 256, 512]] \n",
            "YOLO11s-seg summary: 203 layers, 10,083,836 parameters, 10,083,820 gradients, 33.1 GFLOPs\n",
            "\n",
            "Transferred 561/561 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 10.8MB/s 0.5s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1032.0¬±976.8 MB/s, size: 49.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/merged_dataset/train/labels... 7772 images, 1445 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7773/7773 1.9Kit/s 4.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/merged_dataset/train/images/ds_paper1_0023_jpg.rf.10fb656afde17ad23be9c7b7c7dcd0b8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/merged_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 698.7¬±609.6 MB/s, size: 252.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/merged_dataset/valid/labels... 2747 images, 145 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2747/2747 838.0it/s 3.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/merged_dataset/valid/images/ds_paper1_F_0000_jpg.rf.7154e2bb81c73cdd2961d2508b3712a7.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/merged_dataset/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0004375), 100 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      8.27G     0.5042     0.9266        0.5      1.001         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.1it/s 4:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.4s/it 1:09\n",
            "                   all       2747       3123      0.914      0.863      0.915       0.75      0.898      0.849      0.889      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      8.37G     0.4741      0.739     0.3906     0.9835         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 42.8s\n",
            "                   all       2747       3123      0.929      0.856      0.914      0.744      0.906      0.841      0.887      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      8.11G     0.5026     0.7764     0.4222     0.9953         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.3it/s 39.9s\n",
            "                   all       2747       3123      0.887      0.848      0.904      0.722      0.899      0.826      0.888      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100       7.9G     0.5326      0.822     0.4632      1.011         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.6s\n",
            "                   all       2747       3123      0.863      0.843      0.881      0.701      0.862      0.832      0.865      0.656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      8.45G     0.5392      0.831     0.4793      1.012         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 41.1s\n",
            "                   all       2747       3123      0.881      0.811      0.874      0.685      0.884      0.783      0.844      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      7.88G     0.5352     0.8173     0.4695      1.013         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.1s\n",
            "                   all       2747       3123      0.902       0.83      0.888      0.705      0.891      0.806      0.862      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100       7.9G     0.5261     0.8039     0.4564      1.008         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.7s\n",
            "                   all       2747       3123      0.921      0.821      0.897      0.714      0.908      0.813      0.879      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      7.92G     0.5283     0.7877     0.4546      1.004         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 41.6s\n",
            "                   all       2747       3123      0.849      0.809      0.857      0.659      0.825      0.789      0.823      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      8.07G     0.5278     0.7852     0.4569      1.004         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.7s\n",
            "                   all       2747       3123      0.909      0.828      0.886      0.709      0.885      0.821      0.862      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      8.08G      0.529     0.7818     0.4507      1.009         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.2s\n",
            "                   all       2747       3123      0.897      0.836      0.887      0.708      0.879      0.819      0.861      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      8.06G     0.5215     0.7634     0.4438      1.006         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.5s\n",
            "                   all       2747       3123      0.883      0.832      0.882      0.699      0.865      0.816      0.856      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      8.08G      0.518     0.7654      0.436      1.002         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.9s\n",
            "                   all       2747       3123      0.884      0.843       0.89      0.711       0.87      0.831      0.871      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100       8.1G     0.5227     0.7746     0.4474      1.005         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 41.5s\n",
            "                   all       2747       3123      0.901      0.821      0.884      0.705      0.883      0.805      0.859      0.656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      7.91G     0.5162     0.7489     0.4345     0.9959         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:42\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.3it/s 39.9s\n",
            "                   all       2747       3123      0.907      0.829       0.89      0.715      0.901      0.814      0.866      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100       8.1G     0.5171     0.7492     0.4335     0.9966         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 41.1s\n",
            "                   all       2747       3123       0.89      0.841      0.897      0.726      0.894      0.806      0.873      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      8.09G     0.5078     0.7344     0.4261     0.9936         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 41.3s\n",
            "                   all       2747       3123      0.901      0.835      0.895      0.728      0.892      0.825      0.877       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      7.96G     0.5063     0.7388     0.4222     0.9913         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.5s\n",
            "                   all       2747       3123       0.91      0.839      0.889       0.72      0.899      0.827      0.868      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      8.04G     0.5066     0.7375     0.4236     0.9913         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 41.2s\n",
            "                   all       2747       3123      0.893      0.853      0.891      0.715      0.878      0.833      0.871      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      8.06G     0.4955     0.7331     0.4147     0.9896         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.3s\n",
            "                   all       2747       3123       0.89       0.84      0.879      0.719      0.878      0.831      0.859      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      8.09G     0.4927     0.7205     0.4122     0.9868         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.3it/s 39.1s\n",
            "                   all       2747       3123      0.909      0.828      0.892       0.72       0.89      0.811      0.864      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100       8.1G     0.4945     0.7085     0.4111     0.9873         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 278/278 1.3it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 40.9s\n",
            "                   all       2747       3123      0.906      0.839      0.896      0.733      0.912      0.812      0.878       0.69\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "21 epochs completed in 1.539 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/last.pt, 20.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt, 20.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt...\n",
            "Ultralytics 8.3.237 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s-seg summary (fused): 113 layers, 10,068,364 parameters, 0 gradients, 32.8 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.2it/s 42.9s\n",
            "                   all       2747       3123      0.913      0.865      0.915       0.75      0.898       0.85      0.889      0.696\n",
            "                person        177        333      0.921      0.914      0.963       0.88      0.921      0.913      0.959      0.797\n",
            "                 phone        587        733      0.907      0.797      0.889       0.66      0.894      0.782      0.874      0.611\n",
            "              material       1666       1703      0.982      0.984      0.994       0.97      0.982      0.984      0.994      0.968\n",
            "            headphones        284        354      0.842      0.765      0.812      0.489      0.793       0.72      0.731      0.409\n",
            "Speed: 0.2ms preprocess, 6.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load best.pt from previous run for Transfer Learning\n",
        "model = YOLO('/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt')\n",
        "\n",
        "# Train with new classes (Headphones, Material, etc.)\n",
        "results = model.train(\n",
        "    data='/content/merged_dataset/data.yaml',\n",
        "    epochs=100, # Train for 100 more epochs\n",
        "    imgsz=640,\n",
        "    batch=28,\n",
        "    device=0,\n",
        "    project='/content/drive/MyDrive/Intelligence-Test-Models',\n",
        "    name='anticheat_objects_v2_headphones', # New version name\n",
        "    exist_ok=True,\n",
        "    patience=20\n",
        ")"
      ],
      "id": "Ntx3AoCsMgyk"
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "\n",
        "# Load the best model\n",
        "model_path = '/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Export to ONNX format for web deployment\n",
        "print('\\nüì¶ ƒêang export model sang ONNX...')\n",
        "model.export(\n",
        "    format='onnx',\n",
        "    imgsz=640,\n",
        "    simplify=True,\n",
        "    dynamic=False,\n",
        "    opset=17  # ONNX opset version for better compatibility\n",
        ")\n",
        "\n",
        "# The exported file will be at the same location with .onnx extension\n",
        "onnx_path = model_path.replace('.pt', '.onnx')\n",
        "print(f'\\n‚úÖ Export th√†nh c√¥ng!')\n",
        "print(f'üìç File ONNX: {onnx_path}')\n",
        "\n",
        "# The file is already in the desired output_path after model.export()\n",
        "# The shutil.copy line is redundant and causes a SameFileError.\n",
        "# output_path = '/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/'\n",
        "# shutil.copy(onnx_path, output_path) # This line is removed\n",
        "print(f'üìç File ONNX ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {onnx_path}')\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('üéâ HO√ÄN TH√ÄNH!')\n",
        "print('='*60)\n",
        "print('\\nüìã B∆Ø·ªöC TI·∫æP THEO:')\n",
        "print('1. T·∫£i file ONNX t·ª´ Google Drive v·ªÅ m√°y')\n",
        "print('2. Copy v√†o th∆∞ m·ª•c: Intelligence-Test/public/models/anticheat_yolo11s.onnx')\n",
        "print('3. Deploy l·∫°i web v√† test')\n",
        "print('\\nüí° L∆∞u √Ω: File .pt d√πng ƒë·ªÉ ti·∫øp t·ª•c train, file .onnx d√πng cho web')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaRJELI_yThA",
        "outputId": "89224b07-aebe-4936-e5bb-952abd999f1e"
      },
      "id": "ZaRJELI_yThA",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¶ ƒêang export model sang ONNX...\n",
            "Ultralytics 8.3.237 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLO11s-seg summary (fused): 113 layers, 10,068,364 parameters, 0 gradients, 32.8 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 40, 8400), (1, 32, 160, 160)) (19.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.80...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.5s, saved as '/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.onnx' (38.7 MB)\n",
            "\n",
            "Export complete (4.0s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights\u001b[0m\n",
            "Predict:         yolo predict task=segment model=/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=segment model=/content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.onnx imgsz=640 data=/content/merged_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "\n",
            "‚úÖ Export th√†nh c√¥ng!\n",
            "üìç File ONNX: /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.onnx\n",
            "üìç File ONNX ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: /content/drive/MyDrive/Intelligence-Test-Models/anticheat_objects_v2_headphones/weights/best.onnx\n",
            "\n",
            "============================================================\n",
            "üéâ HO√ÄN TH√ÄNH!\n",
            "============================================================\n",
            "\n",
            "üìã B∆Ø·ªöC TI·∫æP THEO:\n",
            "1. T·∫£i file ONNX t·ª´ Google Drive v·ªÅ m√°y\n",
            "2. Copy v√†o th∆∞ m·ª•c: Intelligence-Test/public/models/anticheat_yolo11s.onnx\n",
            "3. Deploy l·∫°i web v√† test\n",
            "\n",
            "üí° L∆∞u √Ω: File .pt d√πng ƒë·ªÉ ti·∫øp t·ª•c train, file .onnx d√πng cho web\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}